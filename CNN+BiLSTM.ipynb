{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "import pickle\n",
        "import unicodedata"
      ],
      "metadata": {
        "id": "wze6NwcdCMrX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device='cuda'"
      ],
      "metadata": {
        "id": "gR1exsgMEdiE"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df  = pd.read_csv(\"test.csv\")\n",
        "\n",
        "def clean_text(text):\n",
        "    text = str(text)\n",
        "    # Normalize Unicode (so accents and diacritics are consistent)\n",
        "    text = unicodedata.normalize(\"NFKC\", text)\n",
        "    # Remove brackets and dashes\n",
        "    text = re.sub(r'[\\[\\]\\(\\)\\{\\}<>\\-–—]', ' ', text)\n",
        "    # Remove extra whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "train_df['text'] = train_df['text'].apply(clean_text)\n",
        "test_df['text']  = test_df['text'].apply(clean_text)\n",
        "\n",
        "texts  = train_df['text'].astype(str).tolist()\n",
        "labels = train_df['label'].astype(int).tolist()\n",
        "test_texts = test_df['text'].astype(str).tolist()"
      ],
      "metadata": {
        "id": "pgDGdqRICNqK"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_texts = train_df['text'].tolist() + test_df['text'].tolist()\n",
        "vocab = {c: i+2 for i, c in enumerate(sorted(set(''.join(all_texts))))}\n",
        "vocab[\"<PAD>\"] = 0\n",
        "vocab[\"<OOV>\"] = 1\n",
        "\n",
        "# Encode function\n",
        "def encode_text(text):\n",
        "    return [vocab.get(c, 1) for c in text]\n",
        "\n",
        "# Encode training and test data\n",
        "encoded_train = [encode_text(t) for t in train_df['text']]\n",
        "encoded_test  = [encode_text(t) for t in test_df['text']]\n"
      ],
      "metadata": {
        "id": "2yFkKam2CPaA"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 400  # you can increase if your texts are longer\n",
        "\n",
        "def pad_sequences_custom(seqs, max_len=MAX_LEN):\n",
        "    padded = []\n",
        "    for seq in seqs:\n",
        "        if len(seq) < max_len:\n",
        "            seq += [0]*(max_len - len(seq))  # pad with 0 (PAD token)\n",
        "        else:\n",
        "            seq = seq[:max_len]              # truncate if longer\n",
        "        padded.append(seq)\n",
        "    return torch.tensor(padded)\n",
        "\n",
        "X = pad_sequences_custom(encoded_train, MAX_LEN)\n",
        "y = torch.tensor(labels)\n",
        "X_test = pad_sequences_custom(encoded_test, MAX_LEN)\n"
      ],
      "metadata": {
        "id": "fowpq9WhCQax"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "8h5nCfqnGBpf"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 4. Dataset & Dataloaders\n",
        "# -----------------------------\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, X, y=None):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        if self.y is not None:\n",
        "            return self.X[idx], self.y[idx]\n",
        "        return self.X[idx]\n",
        "\n",
        "train_data = TextDataset(X_train, y_train)\n",
        "val_data   = TextDataset(X_val, y_val)\n",
        "test_data  = TextDataset(X_test)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
        "val_loader   = DataLoader(val_data, batch_size=128, shuffle=False)\n",
        "test_loader  = DataLoader(test_data, batch_size=128, shuffle=False)"
      ],
      "metadata": {
        "id": "7zdHT0VkCQQm"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_BiLSTM(nn.Module):\n",
        "    def __init__(self, emb_dim, hidden_dim, n_classes,vocab_size=len(vocab)):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.conv1 = nn.Conv1d(emb_dim, 128, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool1d(2)\n",
        "        self.lstm = nn.LSTM(128, hidden_dim, bidirectional=True, batch_first=True)\n",
        "        self.fc1 = nn.Linear(hidden_dim*2, 128)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(128, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)                # (B, L, E)\n",
        "        x = x.permute(0, 2, 1)               # (B, E, L)\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = self.pool(x)                     # (B, C, L/2)\n",
        "        x = x.permute(0, 2, 1)               # (B, L/2, C)\n",
        "        _, (h, _) = self.lstm(x)\n",
        "        h = torch.cat((h[0], h[1]), dim=1)   # (B, 2H)\n",
        "        x = torch.relu(self.fc1(h))\n",
        "        x = self.dropout(x)\n",
        "        return self.fc2(x)\n"
      ],
      "metadata": {
        "id": "roXiTIhzCWMs"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 6. Setup Training\n",
        "# -----------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = CNN_BiLSTM(vocab_size=len(vocab),\n",
        "                   emb_dim=100,\n",
        "                   hidden_dim=128,\n",
        "                   n_classes=15).to(device)\n",
        "\n",
        "# Class weights\n",
        "class_weights = compute_class_weight(class_weight='balanced',\n",
        "                                     classes=np.unique(y_train.numpy()),\n",
        "                                     y=y_train.numpy())\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "FTue020aDPmZ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 7. Training Loop\n",
        "# -----------------------------\n",
        "EPOCHS = 20\n",
        "best_f1 = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for Xb, yb in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
        "        Xb, yb = Xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(Xb)\n",
        "        loss = criterion(out, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Train Loss: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    preds, trues = [], []\n",
        "    with torch.no_grad():\n",
        "        for Xb, yb in val_loader:\n",
        "            Xb, yb = Xb.to(device), yb.to(device)\n",
        "            out = model(Xb)\n",
        "            pred = torch.argmax(out, dim=1)\n",
        "            preds.extend(pred.cpu().numpy())\n",
        "            trues.extend(yb.cpu().numpy())\n",
        "\n",
        "    f1 = f1_score(trues, preds, average='macro')\n",
        "    print(f\"Validation Macro-F1: {f1:.4f}\")\n",
        "\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        torch.save(model.state_dict(), \"best_cnn_bilstm.pth\")\n",
        "        print(\"✅ Model saved!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLJUrM6ZDPjS",
        "outputId": "704892d5-c18f-415f-c25b-5c03b10d70e0"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/30: 100%|██████████| 748/748 [00:21<00:00, 34.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 2.5129\n",
            "Validation Macro-F1: 0.1590\n",
            "✅ Model saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/30: 100%|██████████| 748/748 [00:21<00:00, 34.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 2.3192\n",
            "Validation Macro-F1: 0.2019\n",
            "✅ Model saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/30: 100%|██████████| 748/748 [00:21<00:00, 35.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 2.2079\n",
            "Validation Macro-F1: 0.2221\n",
            "✅ Model saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/30: 100%|██████████| 748/748 [00:21<00:00, 35.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 2.0989\n",
            "Validation Macro-F1: 0.2475\n",
            "✅ Model saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/30: 100%|██████████| 748/748 [00:21<00:00, 34.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.9913\n",
            "Validation Macro-F1: 0.2494\n",
            "✅ Model saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/30: 100%|██████████| 748/748 [00:21<00:00, 34.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.9043\n",
            "Validation Macro-F1: 0.2628\n",
            "✅ Model saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/30: 100%|██████████| 748/748 [00:21<00:00, 35.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.8173\n",
            "Validation Macro-F1: 0.2801\n",
            "✅ Model saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/30: 100%|██████████| 748/748 [00:21<00:00, 35.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.7027\n",
            "Validation Macro-F1: 0.3001\n",
            "✅ Model saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/30: 100%|██████████| 748/748 [00:21<00:00, 35.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.6513\n",
            "Validation Macro-F1: 0.2790\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/30: 100%|██████████| 748/748 [00:21<00:00, 35.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.5874\n",
            "Validation Macro-F1: 0.2896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/30: 100%|██████████| 748/748 [00:21<00:00, 35.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.5635\n",
            "Validation Macro-F1: 0.2659\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/30: 100%|██████████| 748/748 [00:21<00:00, 35.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.5041\n",
            "Validation Macro-F1: 0.3022\n",
            "✅ Model saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/30: 100%|██████████| 748/748 [00:21<00:00, 35.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.4532\n",
            "Validation Macro-F1: 0.3414\n",
            "✅ Model saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/30: 100%|██████████| 748/748 [00:21<00:00, 35.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.4040\n",
            "Validation Macro-F1: 0.3259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/30: 100%|██████████| 748/748 [00:21<00:00, 35.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.3948\n",
            "Validation Macro-F1: 0.2953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/30: 100%|██████████| 748/748 [00:21<00:00, 35.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.3517\n",
            "Validation Macro-F1: 0.3178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/30: 100%|██████████| 748/748 [00:21<00:00, 35.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.3009\n",
            "Validation Macro-F1: 0.3216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/30: 100%|██████████| 748/748 [00:21<00:00, 35.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.2460\n",
            "Validation Macro-F1: 0.3453\n",
            "✅ Model saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/30: 100%|██████████| 748/748 [00:21<00:00, 35.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.2210\n",
            "Validation Macro-F1: 0.3431\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/30: 100%|██████████| 748/748 [00:21<00:00, 35.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.1801\n",
            "Validation Macro-F1: 0.3502\n",
            "✅ Model saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/30: 100%|██████████| 748/748 [00:21<00:00, 35.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.1399\n",
            "Validation Macro-F1: 0.3273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/30: 100%|██████████| 748/748 [00:21<00:00, 35.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.1919\n",
            "Validation Macro-F1: 0.3232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/30: 100%|██████████| 748/748 [00:21<00:00, 35.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.1043\n",
            "Validation Macro-F1: 0.3305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/30: 100%|██████████| 748/748 [00:21<00:00, 35.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.0587\n",
            "Validation Macro-F1: 0.3300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/30: 100%|██████████| 748/748 [00:21<00:00, 35.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.0632\n",
            "Validation Macro-F1: 0.3490\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/30: 100%|██████████| 748/748 [00:21<00:00, 35.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.0631\n",
            "Validation Macro-F1: 0.3304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/30: 100%|██████████| 748/748 [00:21<00:00, 35.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.0299\n",
            "Validation Macro-F1: 0.3406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/30: 100%|██████████| 748/748 [00:21<00:00, 35.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.9756\n",
            "Validation Macro-F1: 0.3399\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/30: 100%|██████████| 748/748 [00:21<00:00, 35.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.9806\n",
            "Validation Macro-F1: 0.3346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/30: 100%|██████████| 748/748 [00:21<00:00, 35.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.9341\n",
            "Validation Macro-F1: 0.3346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 8. Inference on Test Set\n",
        "# -----------------------------\n",
        "model.load_state_dict(torch.load(\"best_cnn_bilstm.pth\"))\n",
        "model.eval()\n",
        "\n",
        "test_preds = []\n",
        "with torch.no_grad():\n",
        "    for Xb in tqdm(test_loader, desc=\"Predicting\"):\n",
        "        Xb = Xb.to(device)\n",
        "        out = model(Xb)\n",
        "        pred = torch.argmax(out, dim=1)\n",
        "        test_preds.extend(pred.cpu().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKgk8UB-DPgT",
        "outputId": "c4f6bee7-fff1-4d90-ba6e-fab5381e8cef"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting: 100%|██████████| 234/234 [00:02<00:00, 96.33it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame({\n",
        "    \"id\": test_df[\"id\"],\n",
        "    \"label\": test_preds\n",
        "})\n",
        "submission.to_csv(\"prediction_rnn+bilstm.csv\", index=False)\n",
        "print(\"✅ Submission saved as prediction_rnn+bilstm.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EMIvppuDXbj",
        "outputId": "7cd44056-f590-4ec1-8a79-451e8e4aae01"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Submission saved as prediction_rnn+bilstm.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 10. Save Artifacts\n",
        "# -----------------------------\n",
        "torch.save(model.state_dict(), \"cnn_bilstm_final.pth\")\n",
        "with open(\"vocab.pkl\", \"wb\") as f:\n",
        "    pickle.dump(vocab, f)\n",
        "print(\"✅ Model and vocab saved!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bayLeifXDZJu",
        "outputId": "8125a755-c3db-4832-8c5c-556abdb03887"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model and vocab saved!\n"
          ]
        }
      ]
    }
  ]
}